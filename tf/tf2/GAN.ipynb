{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Generative Network\n",
    "\n",
    "The intention of this notebook is to create a GAN to generate realistic handwritten digest from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from utils.mnist_dataset import MNIST_Dataset\n",
    "from utils.batch import make_batches_all, make_batches_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(int(tf.__version__[0])==2)  # Use TensorFlow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check computing units\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = 'log-GAN'  # For tensorboard, etc.\n",
    "\n",
    "DS_PATH = 'data' # Where de MNIST dataset is located\n",
    "\n",
    "# Hyperparams\n",
    "PARAMS = {\n",
    "    'generator': {\n",
    "        'learning_rate': 0.00001\n",
    "    },\n",
    "    'discriminator': {\n",
    "        'learning_rate': 0.00001\n",
    "    },\n",
    "    'latent_factors': 100,\n",
    "    'epochs': 200,\n",
    "    'batch_size': 64,  # Use an even number\n",
    "    'disc_gen_ratio': 1  # How many times over the generator the discriminator is trained.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash download_mnist.sh {DS_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "        \n",
    "    def __init__(self, ds_path):\n",
    "        self.ds = MNIST_Dataset(ds_path)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _preprocess_samples(x):\n",
    "        \"\"\"x: tensor of shape (-1, 28, 28) representing the images.\n",
    "        \"\"\"\n",
    "        n,w,h = x.shape\n",
    "        # From 28x28 pixels to 32x32\n",
    "        x_32 = np.pad(\n",
    "            x,\n",
    "            pad_width=((0,0),(2,2),(2,2)),\n",
    "            mode='constant',\n",
    "            constant_values=0\n",
    "        )\n",
    "        x_scaled = (x_32/128)-1 # Scaled -1,1\n",
    "        return x_scaled.reshape(n,32,32,1)\n",
    "    \n",
    "    \n",
    "    def train_data(self):\n",
    "        x,y = self.ds.get_train()\n",
    "        return (\n",
    "            self._preprocess_samples(x).astype(np.float32),\n",
    "            y\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "\n",
    "This model tries to generate realistic images.\n",
    "-  INPUT: Noise vector (1x100).\n",
    "-  OUTPUT: Image (32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(latent_factors):\n",
    "    \"\"\" From noise to plausible examples.\n",
    "    INPUT: Noise vector of latent factors (-1,1)\n",
    "    OUTPUT: 32x32x1 (-1,1) grayscale image\n",
    "    \"\"\"\n",
    "    return tf.keras.Sequential(\n",
    "        name=\"Generator\",\n",
    "        layers=[\n",
    "            tf.keras.layers.InputLayer(\n",
    "                input_shape=(latent_factors)\n",
    "            ),\n",
    "            tf.keras.layers.Dense(  \n",
    "                name=\"D1\",\n",
    "                units=128,\n",
    "                activation=tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "            ),\n",
    "            tf.keras.layers.Dense(  \n",
    "                name=\"D2\",\n",
    "                units=256,\n",
    "                activation=tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "            ),\n",
    "            tf.keras.layers.Dense(  \n",
    "                name=\"D3\",\n",
    "                units=512,\n",
    "                activation=tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(\n",
    "                momentum=0.8,\n",
    "                name=\"BN1\"\n",
    "            ),\n",
    "            tf.keras.layers.Dense(  \n",
    "                name=\"D4\",\n",
    "                units=1024,\n",
    "                activation=tf.math.tanh\n",
    "            ),\n",
    "            # Reshape 120->1x1x120\n",
    "            tf.keras.layers.Reshape(\n",
    "                target_shape=(32,32,1)\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "This model tells the image probability of being real.\n",
    "-  INPUT: Image (32x32).\n",
    "-  OUTPUT: Probability (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator():\n",
    "    \"\"\"Output the probability for an example to be real.\n",
    "    \"\"\"\n",
    "    return tf.keras.Sequential(\n",
    "        name=\"Discriminator\",\n",
    "        layers=[\n",
    "            tf.keras.layers.InputLayer(\n",
    "                input_shape=(32,32,1)\n",
    "            ),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(  \n",
    "                name=\"F3\",\n",
    "                units=512,\n",
    "                activation=tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "            ),\n",
    "            tf.keras.layers.Dense(  \n",
    "                name=\"F4\",\n",
    "                units=256,\n",
    "                activation=tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "            ),\n",
    "            tf.keras.layers.Dense(  \n",
    "                name=\"F5\",\n",
    "                units=1,\n",
    "                activation=tf.math.sigmoid\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversarial Network\n",
    "\n",
    "This model represents the pipeline of the GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gan(generator, discriminator):\n",
    "    return tf.keras.Sequential(\n",
    "        name=\"GAN\",\n",
    "        layers=[\n",
    "            tf.keras.layers.InputLayer(\n",
    "                input_shape=(\n",
    "                    generator.layers[0].input.shape[1]\n",
    "                )\n",
    "            ),\n",
    "            generator,\n",
    "            discriminator\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = get_generator(PARAMS['latent_factors'])\n",
    "gen_opt = tf.keras.optimizers.Adam(\n",
    "    learning_rate=PARAMS['generator']['learning_rate']\n",
    ")\n",
    "\n",
    "discriminator = get_discriminator()\n",
    "disc_opt = tf.keras.optimizers.Adam(\n",
    "    learning_rate=PARAMS['discriminator']['learning_rate']\n",
    ")\n",
    "\n",
    "gan = get_gan(generator, discriminator)\n",
    "\n",
    "generator.summary()\n",
    "discriminator.summary()\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_latent_factors(n):\n",
    "    \"\"\"Noise sample function.\n",
    "    \"\"\"\n",
    "    return tf.random.uniform(shape=(n, PARAMS['latent_factors']), minval=-1.0, maxval=1.0)  # Naive way.\n",
    "    #return tf.random.normal(shape=(n, PARAMS['latent_factors']), mean=0.0, stddev=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(epoch, images, path_out, dim=(10,10), figsize=(32,32)):\n",
    "    epoch = str(epoch).rjust(3,\"0\")\n",
    "    generated_images = images.reshape(-1,32,32)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Epoch: {}'.format(epoch), fontsize=75, horizontalalignment='center', verticalalignment='top', backgroundcolor=\"black\", color='yellow', weight='bold')\n",
    "    plt.savefig(path_out + '/generator_{}.png'.format(epoch))\n",
    "    plt.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, fn_loss, x_train, y_train):\n",
    "    \"\"\"Training step for a model.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_train, training=True)\n",
    "        loss = fn_loss(y_train, predictions)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_loss(y_true, y_pred):\n",
    "    \"\"\"Loss function.\n",
    "    Log loss or cross-entropy.\n",
    "    \n",
    "    NOTE: it is possible to use tf.keras.losses.BinaryCrossentropy() alone.\n",
    "    param reduction='SUM_OVER_BATCH_SIZE'  works the same.\n",
    "    \"\"\"\n",
    "    return tf.math.reduce_mean(\n",
    "        tf.keras.losses.binary_crossentropy(\n",
    "            y_true=y_true,\n",
    "            y_pred=y_pred,\n",
    "            label_smoothing = 0,  # Not useful since I only need one sided label smoothing\n",
    "            from_logits=False\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard writers\n",
    "\n",
    "log_dir = LOG_PATH + '/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "gen_summary_writer = tf.summary.create_file_writer(log_dir + '/gen')\n",
    "disc_summary_writer = tf.summary.create_file_writer(log_dir + '/disc')\n",
    "\n",
    "img_out_dir = log_dir + '/imgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {img_out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "ds = Dataset(DS_PATH)\n",
    "x_real, _ = ds.train_data()  # I don't care about labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precalculate batch labels to gain speed.\n",
    "\n",
    "bs = PARAMS['batch_size']\n",
    "n_batches = math.ceil(len(x_real)*2 / bs) # Real + Fake data / batch_size\n",
    "\n",
    "# Discriminator labels\n",
    "disc_y = tf.concat(\n",
    "    [\n",
    "        tf.fill((bs//2,1), 0.95), # Real. One sided label smoothing\n",
    "        tf.fill((bs//2,1), 0.0)   # Fake\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "# Generator labels\n",
    "gen_y = tf.fill((bs,1), 1.0)  # Do not smooth generator samples!!\n",
    "\n",
    "assert(len(disc_y)==len(gen_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(generator, discriminator, val_data_real, val_data_fake):\n",
    "    n = len(val_data_real)\n",
    "    y_true = tf.concat([tf.fill((n,1), 1.0),tf.fill((n,1), 0.0)], axis=0)\n",
    "    y_pred = discriminator( tf.concat([val_data_real, val_data_fake ],axis=0) )\n",
    "    y_true_bin = y_true.numpy().flatten()\n",
    "    y_pred_bin = np.where(y_pred.numpy().flatten()>=0.5, 1, 0)\n",
    "\n",
    "    # Metrics\n",
    "    cf = sklearn.metrics.confusion_matrix(y_true, y_pred_bin)\n",
    "    tn, fp, fn, tp = cf.ravel()\n",
    "    return {\n",
    "        'disc_loss': fn_loss(y_true, y_pred),\n",
    "        'gen_loss': fn_loss(tf.fill((n,1), 1.0), discriminator(val_data_fake)),\n",
    "        'acc': sklearn.metrics.accuracy_score(y_true, y_pred_bin),\n",
    "        'fpr': fp/(fp+tn), # False positive ratio\n",
    "        'cm': cf\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "\n",
    "We will track the metrics evolution and the generated images with Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taining loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Training loop.\n",
    "\n",
    "Use tensorboard to see examples and what is happening.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Generator for real data, random sampling strategy\n",
    "x_real_g=make_batches_random(\n",
    "    x=x_real,\n",
    "    y=None,\n",
    "    batch_size=bs//2,\n",
    "    stop_after_epoch=False\n",
    ")\n",
    "\n",
    "# Validation data\n",
    "val_data_real=np.take(  # Real samples\n",
    "    a=x_real,\n",
    "    indices=np.random.randint(\n",
    "        low=0,\n",
    "        high=len(x_real), \n",
    "        size=256\n",
    "    ),\n",
    "    axis=0\n",
    ")\n",
    "val_params_fake = sample_latent_factors(256)\n",
    "\n",
    "\n",
    "for epoch in range(0, PARAMS['epochs']):  \n",
    "    # Batch\n",
    "    with tqdm_notebook(total=n_batches, unit='batch', desc=\"Epoch: {} \".format(epoch)) as pbar:\n",
    "        for n_batch in range(n_batches):\n",
    "            for i in range(PARAMS['disc_gen_ratio']):\n",
    "                # DISCRIMINATOR\n",
    "                _, disc_x_real, _ = x_real_g.__next__()\n",
    "                disc_x = tf.concat([\n",
    "                    disc_x_real,\n",
    "                    generator(sample_latent_factors(bs//2))  # Fake data\n",
    "                ], axis=0)\n",
    "                discriminator.trainable=True\n",
    "                disc_b_loss = train_step(\n",
    "                    model=discriminator,\n",
    "                    optimizer=disc_opt,\n",
    "                    fn_loss=fn_loss,\n",
    "                    x_train=disc_x,\n",
    "                    y_train=disc_y\n",
    "                )    \n",
    "            # GENERATOR\n",
    "            discriminator.trainable=False\n",
    "            gen_b_loss = train_step(\n",
    "                model=gan,  # Latent params -> Generator -> image -> Discriminator -> Probability\n",
    "                optimizer=gen_opt,\n",
    "                fn_loss=fn_loss,\n",
    "                x_train=sample_latent_factors(bs),\n",
    "                y_train=gen_y\n",
    "            )\n",
    "\n",
    "            #Update progress bar\n",
    "            pbar.set_postfix(disc_loss=disc_b_loss.numpy(), gen_loss=gen_b_loss.numpy())\n",
    "            pbar.update(1)\n",
    "\n",
    "        \n",
    "    # EPOCH METRICS\n",
    "    val_data_fake = generator(val_params_fake)\n",
    "    val_metrics = evaluate(generator, discriminator, val_data_real, val_data_fake)\n",
    "    for m in ['disc_loss','acc','gen_loss','fpr','cm']:\n",
    "        print(\"{}\\t{}\".format(m, val_metrics[m]))\n",
    "    \n",
    "    with disc_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', val_metrics[\"disc_loss\"], step=epoch)\n",
    "        tf.summary.scalar('acc', val_metrics[\"acc\"], step=epoch)\n",
    "    with gen_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', val_metrics[\"gen_loss\"], step=epoch)\n",
    "        tf.summary.scalar('fpr', val_metrics[\"fpr\"], step=epoch)\n",
    "        tf.summary.image(\"Training data\", val_data_fake, step=epoch, max_outputs=25)\n",
    "    \n",
    "    if epoch%2 == 0:\n",
    "        plot_generated_images(epoch, val_data_fake.numpy()[:100], img_out_dir) # Output generated images   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a gif with the progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!convert -resize 25% -delay 100 -loop 0 {log_dir}/imgs/*.png img/gan/evolution.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/gan/evolution.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = generator(sample_latent_factors(1))[0].numpy().reshape(32,32)\n",
    "print(\"Disc prob: {}\".format(discriminator(sample.reshape(-1,32,32,1)).numpy()[0][0]))\n",
    "\n",
    "plt.imshow(\n",
    "    sample, \n",
    "    cmap='gray'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "tf.saved_model.save(generator, log_dir + '/saved_generator')\n",
    "tf.saved_model.save(discriminator, log_dir + '/saved_discriminator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & use the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "tf_gen = tf.saved_model.load(log_dir + '/saved_generator')\n",
    "\n",
    "# Serving function\n",
    "infer_gen = tf_gen.signatures['serving_default']\n",
    "# Model input\n",
    "print(\"Model input: \\n\\t{}\".format(infer_gen.structured_input_signature))\n",
    "# Model output\n",
    "print(\"Model output layer \\n\\t{}\".format(infer_gen.structured_outputs))\n",
    "\n",
    "# Serving function\n",
    "generate = lambda x: infer_gen(x)['reshape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "tf_disc = tf.saved_model.load(log_dir + '/saved_discriminator')\n",
    "\n",
    "# Serving function\n",
    "infer_disc = tf_disc.signatures['serving_default']\n",
    "# Model input\n",
    "print(\"Model input: \\n\\t{}\".format(infer_disc.structured_input_signature))\n",
    "# Model output\n",
    "print(\"Model output layer \\n\\t{}\".format(infer_disc.structured_outputs))\n",
    "\n",
    "# Serving function\n",
    "discriminate = lambda x: infer_disc(x)['F5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = generate(sample_latent_factors(1))\n",
    "\n",
    "print(\"Disc prob: {}\".format(discriminate(samples).numpy()[0][0]))\n",
    "\n",
    "plt.imshow(\n",
    "    samples[0].numpy().reshape(32,32), \n",
    "    cmap='gray'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem using keras\n",
    "discriminator.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. <a name=\"bib-web-gantf\"></a>[Building a simple Generative Adversarial Network (GAN) using TensorFlow](https://blog.paperspace.com/implementing-gans-in-tensorflow/)\n",
    "2. <a name=\"bib-web-adversarialtf\"></a>[Generative Adversarial Nets in TensorFlow](https://wiseodd.github.io/techblog/2016/09/17/gan-tensorflow/)\n",
    "3. <a name=\"bib-web-gankeras\"></a>[Generative Adversarial Network(GAN) using Keras](https://medium.com/datadriveninvestor/generative-adversarial-network-gan-using-keras-ce1c05cfdfd3)\n",
    "4. <a name=\"bib-web-poolstride\"></a>[Pooling VS Striding - Striving for Simplicity: The All Convolutional Net](https://arxiv.org/abs/1412.6806)\n",
    "5. <a name=\"bib-web-collapse1\"></a>[Mode collapse: GAN — Why it is so hard to train Generative Adversarial Networks!](https://medium.com/@jonathan_hui/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b)\n",
    "6. <a name=\"bib-web-collapse2\"></a>[Mode collapse: What does it mean if all produced images of a GAN look the same?](https://www.quora.com/What-does-it-mean-if-all-produced-images-of-a-GAN-look-the-same)\n",
    "7. <a name=\"bib-vid-gans\"></a>[NIPS 2016 - Generative Adversarial Networks - Ian Goodfellow](https://www.youtube.com/watch?v=AJVyzd0rqdc)\n",
    "  1. [On divergence](https://www.youtube.com/watch?v=AJVyzd0rqdc&t=52m10s)\n",
    "  1. [On labeled/conditioned GANS](https://www.youtube.com/watch?v=AJVyzd0rqdc&t=1h09m50s)\n",
    "  1. [On mode collapse](https://www.youtube.com/watch?v=AJVyzd0rqdc&t=1h31m53s)\n",
    "  1. [One sided label smoothing](https://www.youtube.com/watch?v=AJVyzd0rqdc&t=1h11m34s)\n",
    "  1. [Question: GANs vs VAEs](https://www.youtube.com/watch?v=AJVyzd0rqdc&t=37m10s)\n",
    "  1. [Question: Sampling distributions uniform VS Norma](https://www.youtube.com/watch?v=AJVyzd0rqdc&t=37m57s)\n",
    "  1. [Question: mode collapse/same sample](https://www.youtube.com/watch?v=AJVyzd0rqdc&t=35m47s)\n",
    "8.  <a name=\"bib-web-tbstarted\"></a>[Get started with TensorBoard](https://www.tensorflow.org/tensorboard/r2/get_started#using_tensorboard_with_other_methods)\n",
    "9. <a name=\"bib-web-codegan1\"></a>[Github: PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py)\n",
    "10. [TQDM (status bar library)](https://tqdm.github.io/)\n",
    "11. [Inside TensorFlow: Summaries and TensorBoard](https://www.youtube.com/watch?v=OI4cskHUslQ)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
